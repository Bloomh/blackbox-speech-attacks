{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_attack_results/an4-v2-THE_JUICE_OF_LEMONS_MAKES_FINE_PUNCH-5683-32866-0027.csv',\n",
       " 'batch_attack_results/librispeech-v2-THE_HARDER_HE_TRIED_THE_LESS_HE_GOT_DONE-5683-32866-0027.csv',\n",
       " 'batch_attack_results/an4-v1-A_CRAMP_IS_NO_SMALL_DANGER_ON_A_SWIM-1188-133604-0043.csv',\n",
       " 'batch_attack_results/an4-v1-THE_GRASS_CURLED_AROUND_THE_FENCE_POST-4507-16021-0015.csv',\n",
       " 'batch_attack_results/librispeech-v2-THE_PENNANT_WAVED_WHEN_THE_WIND_BLEW-260-123440-0008.csv',\n",
       " 'batch_attack_results/an4-v2-A_CRAMP_IS_NO_SMALL_DANGER_ON_A_SWIM-1089-134691-0005.csv',\n",
       " 'batch_attack_results/ted-v2-A_CRAMP_IS_NO_SMALL_DANGER_ON_A_SWIM-260-123440-0008.csv',\n",
       " 'batch_attack_results/ted-v1-THE_HEART_BEAT_STRONGLY_AND_WITH_FIRM_STROKES-1188-133604-0043.csv',\n",
       " 'batch_attack_results/ted-v2-A_POUND_OF_SUGAR_COSTS_MORE_THAN_EGGS-5683-32866-0027.csv',\n",
       " 'batch_attack_results/ted-v1-THE_HEART_BEAT_STRONGLY_AND_WITH_FIRM_STROKES-1089-134691-0005.csv',\n",
       " 'batch_attack_results/an4-v2-THE_PENNANT_WAVED_WHEN_THE_WIND_BLEW-5683-32866-0027.csv',\n",
       " 'batch_attack_results/librispeech-v1-THE_YOUNG_KID_JUMPED_THE_RUSTY_GATE-260-123440-0008.csv',\n",
       " 'batch_attack_results/an4-v1-THE_JUICE_OF_LEMONS_MAKES_FINE_PUNCH-5683-32866-0027.csv',\n",
       " 'batch_attack_results/ted-v1-OAK_IS_STRONG_AND_ALSO_GIVES_SHADE-1089-134691-0005.csv',\n",
       " 'batch_attack_results/ted-v2-OAK_IS_STRONG_AND_ALSO_GIVES_SHADE-260-123440-0008.csv',\n",
       " 'batch_attack_results/librispeech-v1-A_CRAMP_IS_NO_SMALL_DANGER_ON_A_SWIM-1188-133604-0043.csv',\n",
       " 'batch_attack_results/librispeech-v1-A_YACHT_SLID_AROUND_THE_POINT_INTO_THE_BAY-1089-134691-0005.csv',\n",
       " 'batch_attack_results/librispeech-v2-A_CRAMP_IS_NO_SMALL_DANGER_ON_A_SWIM-1089-134691-0005.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Directory containing batch attack results\n",
    "results_dir = 'batch_attack_results'\n",
    "\n",
    "# 1. List all summary and per-run CSVs\n",
    "all_csvs = glob.glob(os.path.join(results_dir, '*.csv'))\n",
    "all_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        adv_wav_path  \\\n",
      "0  batch_attack_results/an4-v2-THE_JUICE_OF_LEMON...   \n",
      "1  batch_attack_results/librispeech-v2-THE_HARDER...   \n",
      "2  batch_attack_results/an4-v1-A_CRAMP_IS_NO_SMAL...   \n",
      "3  batch_attack_results/an4-v1-THE_GRASS_CURLED_A...   \n",
      "4  batch_attack_results/librispeech-v2-THE_PENNAN...   \n",
      "\n",
      "                              input_wav  \\\n",
      "0   processed_sound/5683-32866-0027.wav   \n",
      "1   processed_sound/5683-32866-0027.wav   \n",
      "2  processed_sound/1188-133604-0043.wav   \n",
      "3   processed_sound/4507-16021-0015.wav   \n",
      "4   processed_sound/260-123440-0008.wav   \n",
      "\n",
      "                            target_sentence target_model target_version  \\\n",
      "0      THE JUICE OF LEMONS MAKES FINE PUNCH          an4             v2   \n",
      "1  THE HARDER HE TRIED THE LESS HE GOT DONE  librispeech             v2   \n",
      "2      A CRAMP IS NO SMALL DANGER ON A SWIM          an4             v1   \n",
      "3    THE GRASS CURLED AROUND THE FENCE POST          an4             v1   \n",
      "4      THE PENNANT WAVED WHEN THE WIND BLEW  librispeech             v2   \n",
      "\n",
      "                                     ensemble_models  \\\n",
      "0  [{\"training_set\": \"an4\", \"version\": \"v1\"}, {\"t...   \n",
      "1  [{\"training_set\": \"an4\", \"version\": \"v1\"}, {\"t...   \n",
      "2  [{\"training_set\": \"an4\", \"version\": \"v2\"}, {\"t...   \n",
      "3  [{\"training_set\": \"an4\", \"version\": \"v2\"}, {\"t...   \n",
      "4  [{\"training_set\": \"an4\", \"version\": \"v1\"}, {\"t...   \n",
      "\n",
      "                                       attack_params  \\\n",
      "0  {\"epsilon\": 0.03, \"alpha\": 0.001, \"PGD_iter\": ...   \n",
      "1  {\"epsilon\": 0.03, \"alpha\": 0.001, \"PGD_iter\": ...   \n",
      "2  {\"epsilon\": 0.03, \"alpha\": 0.001, \"PGD_iter\": ...   \n",
      "3  {\"epsilon\": 0.03, \"alpha\": 0.001, \"PGD_iter\": ...   \n",
      "4  {\"epsilon\": 0.03, \"alpha\": 0.001, \"PGD_iter\": ...   \n",
      "\n",
      "                                         target_pred  \\\n",
      "0     PY TWELVNE THREE U INE E ITY FIRT NINE C SEVEN   \n",
      "1  A COLD TRIGHT MONION WAS SHININGLY CREA SHARP ...   \n",
      "2                C A Y E L  U C V FIVE VI D FIE FIVE   \n",
      "3                              AI FOA A  E OVE UR AH   \n",
      "4  I'LL TRY IF I KNOW ALL OF THE THINGS I USED TO...   \n",
      "\n",
      "                   target_lev_dists  \\\n",
      "0  [34, 33, 34, 34, 33, 32, 34, 33]   \n",
      "1  [48, 52, 53, 50, 48, 55, 53, 52]   \n",
      "2  [30, 31, 31, 31, 31, 32, 31, 31]   \n",
      "3  [28, 29, 28, 28, 29, 30, 29, 29]   \n",
      "4  [35, 34, 37, 35, 34, 38, 38, 35]   \n",
      "\n",
      "                                  ensemble_lev_dists  max_db_diff  \n",
      "0  [[27, 28, 29, 26, 26, 28, 27, 26], [45, 46, 37...     0.024893  \n",
      "1  [[28, 28, 27, 28, 28, 27, 28, 27], [45, 41, 46...     0.021291  \n",
      "2  [[38, 41, 37, 37, 34, 33, 35, 35], [59, 56, 55...     0.008788  \n",
      "3  [[32, 34, 29, 32, 29, 29, 29, 30], [33, 32, 33...     0.020273  \n",
      "4  [[31, 31, 30, 30, 31, 27, 29, 28], [31, 29, 30...     0.010726  \n",
      "Combined DataFrame shape: (18, 11)\n"
     ]
    }
   ],
   "source": [
    "# combine all of the per_run_csvs into a single dataframe\n",
    "dfs = [pd.read_csv(f) for f in all_csvs]\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "print(df_all.head())\n",
    "print(f\"Combined DataFrame shape: {df_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [34, 33, 34, 34, 33, 32, 34, 33]\n",
      "1     [48, 52, 53, 50, 48, 55, 53, 52]\n",
      "2     [30, 31, 31, 31, 31, 32, 31, 31]\n",
      "3     [28, 29, 28, 28, 29, 30, 29, 29]\n",
      "4     [35, 34, 37, 35, 34, 38, 38, 35]\n",
      "5     [40, 38, 36, 35, 35, 35, 36, 37]\n",
      "6     [35, 37, 35, 37, 38, 34, 37, 36]\n",
      "7     [55, 56, 58, 57, 56, 56, 56, 56]\n",
      "8     [45, 47, 42, 44, 44, 45, 46, 45]\n",
      "9     [47, 47, 46, 48, 47, 48, 46, 47]\n",
      "10    [31, 31, 34, 34, 34, 39, 38, 35]\n",
      "11    [33, 31, 31, 32, 31, 32, 34, 31]\n",
      "12    [28, 28, 27, 29, 29, 30, 30, 30]\n",
      "13    [50, 51, 48, 48, 49, 50, 49, 50]\n",
      "14    [38, 35, 36, 34, 40, 38, 37, 39]\n",
      "15    [61, 60, 60, 61, 58, 59, 58, 59]\n",
      "16    [54, 56, 58, 56, 55, 55, 53, 55]\n",
      "17    [54, 54, 55, 54, 54, 54, 52, 56]\n",
      "Name: target_lev_dists, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# plot a histogram of the final Levenshtein distance for each attack\n",
    "print(df_all['target_lev_dists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Target Loss ---\n",
    "loss_lists = [ast.literal_eval(x) for x in df_all[\"target_loss_hist\"].dropna()]\n",
    "max_len = max(len(lst) for lst in loss_lists)\n",
    "loss_array = np.full((len(loss_lists), max_len), np.nan)\n",
    "for i, lst in enumerate(loss_lists):\n",
    "    loss_array[i, :len(lst)] = lst\n",
    "mean_target_loss = np.nanmean(loss_array, axis=0)\n",
    "\n",
    "# --- Ensemble Loss ---\n",
    "ensemble_loss_lists = [ast.literal_eval(x) for x in df_all[\"ensemble_loss_hists\"].dropna()]\n",
    "# Flatten to shape: (runs, ensemble_models, steps)\n",
    "max_ens = max(len(run) for run in ensemble_loss_lists)\n",
    "max_steps = max(len(model) for run in ensemble_loss_lists for model in run)\n",
    "ens_loss_array = np.full((len(ensemble_loss_lists), max_ens, max_steps), np.nan)\n",
    "for i, run in enumerate(ensemble_loss_lists):\n",
    "    for j, model in enumerate(run):\n",
    "        ens_loss_array[i, j, :len(model)] = model\n",
    "# Mean over runs and ensemble models\n",
    "mean_ensemble_loss = np.nanmean(ens_loss_array, axis=(0,1))\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(mean_target_loss, marker='o', label='Mean Target Loss')\n",
    "plt.plot(mean_ensemble_loss, marker='s', label='Mean Ensemble Loss')\n",
    "plt.xlabel('PGD Iteration')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.title('Mean Loss at Each PGD Iteration (Target vs Ensemble)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Target Lev Dist ---\n",
    "target_lev_dists = [ast.literal_eval(x) for x in df_all[\"target_lev_dists\"].dropna()]\n",
    "max_len = max(len(lst) for lst in target_lev_dists)\n",
    "target_lev_array = np.full((len(target_lev_dists), max_len), np.nan)\n",
    "for i, lst in enumerate(target_lev_dists):\n",
    "    target_lev_array[i, :len(lst)] = lst\n",
    "mean_target_lev = np.nanmean(target_lev_array, axis=0)\n",
    "\n",
    "# --- Ensemble Lev Dist ---\n",
    "ensemble_lev_dists = [ast.literal_eval(x) for x in df_all[\"ensemble_lev_dists\"].dropna()]\n",
    "# Flatten to shape: (runs, ensemble_models, steps)\n",
    "max_ens = max(len(run) for run in ensemble_lev_dists)\n",
    "max_steps = max(len(model) for run in ensemble_lev_dists for model in run)\n",
    "ens_lev_array = np.full((len(ensemble_lev_dists), max_ens, max_steps), np.nan)\n",
    "for i, run in enumerate(ensemble_lev_dists):\n",
    "    for j, model in enumerate(run):\n",
    "        ens_lev_array[i, j, :len(model)] = model\n",
    "# Mean over runs and ensemble models\n",
    "mean_ensemble_lev = np.nanmean(ens_lev_array, axis=(0,1))\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(mean_target_lev, marker='o', label='Mean Target Lev Dist')\n",
    "plt.plot(mean_ensemble_lev, marker='s', label='Mean Ensemble Lev Dist')\n",
    "plt.xlabel('PGD Iteration')\n",
    "plt.ylabel('Mean Lev Dist')\n",
    "plt.title('Mean Lev Dist at Each PGD Iteration (Target vs Ensemble)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
